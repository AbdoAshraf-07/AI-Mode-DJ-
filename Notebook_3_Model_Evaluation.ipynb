{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644227a6",
   "metadata": {},
   "source": [
    "# Notebook 3: Model Evaluation & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed86edd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff5d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17eac59",
   "metadata": {},
   "source": [
    "## Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d7eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Evaluation will run on: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb758daa",
   "metadata": {},
   "source": [
    "## Model Architecture (Same as Notebook 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDeepEmotionNet(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11576c0f",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ecebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dir = r\"DATA/DATASET/test\"\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class_names = test_dataset.classes\n",
    "print(\"Classes:\", class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd918ea7",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model_path = \"custom_emotion_model.pth\"\n",
    "model = CustomDeepEmotionNet(num_classes=len(class_names)).to(device)\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    print(\"Model weights loaded successfully.\")\n",
    "else:\n",
    "    print(\"WARNING: Model file not found.\")\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5d316",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Running Inference\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5abea8",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e642a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fe4694",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfdce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Emotion Recognition - Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba4870",
   "metadata": {},
   "source": [
    "## Visual Test Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6828e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_test_samples(dataset, model, num_samples=5):\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        image, label = dataset[idx]\n",
    "        input_tensor = image.unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            _, pred = torch.max(output, 1)\n",
    "\n",
    "        img_display = image.permute(1, 2, 0) * 0.5 + 0.5\n",
    "        color = \"green\" if pred.item() == label else \"red\"\n",
    "\n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        plt.imshow(img_display)\n",
    "        plt.title(f\"True: {class_names[label]}\\nPred: {class_names[pred.item()]}\", color=color)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_test_samples(test_dataset, model)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
